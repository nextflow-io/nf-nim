# This file is generated by extract-openapi.py and should not be changed by hand.
openapi: 3.1.0
info:
  title: NVIDIA NIM for LLMs
  summary: Accelerated LLM inference for NVIDIA GPUs.
  version: 1.8.4
paths:
  /v1/chat/completions:
    post:
      summary: OpenAI-compatible chat endpoint
      operationId: create_chat_completion_v1_chat_completions_post
      parameters:
      - name: content-type
        in: header
        required: false
        schema:
          anyOf:
          - type: string
          - type: 'null'
          title: Content-Type
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/NIMLLMChatCompletionRequest'
      responses:
        '200':
          description: Successful Response
          content:
            application/json:
              schema:
                anyOf:
                - $ref: '#/components/schemas/vllm__entrypoints__openai__protocol__ChatCompletionResponse'
                - $ref: '#/components/schemas/ChatCompletionStreamResponse'
                title: Response Create Chat Completion V1 Chat Completions Post
        '400':
          description: Received an invalid request possibly containing unsupported
            or out-of-range parameter values.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
        '404':
          description: The requested model does not exist.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
        '500':
          description: Internal Server Error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
        '415':
          description: Unsupported Media Type
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
        '422':
          description: Validation Error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/HTTPValidationError'
  /v1/completions:
    post:
      summary: OpenAI-compatible completions endpoint
      operationId: create_completion_v1_completions_post
      parameters:
      - name: content-type
        in: header
        required: false
        schema:
          anyOf:
          - type: string
          - type: 'null'
          title: Content-Type
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/NIMLLMCompletionRequest'
      responses:
        '200':
          description: Successful Response
          content:
            application/json:
              schema:
                anyOf:
                - $ref: '#/components/schemas/vllm__entrypoints__openai__protocol__CompletionResponse'
                - $ref: '#/components/schemas/CompletionStreamResponse'
                title: Response Create Completion V1 Completions Post
        '400':
          description: Received an invalid request possibly containing unsupported
            or out-of-range parameter values.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
        '404':
          description: The requested model does not exist.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
        '500':
          description: Internal Server Error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
        '415':
          description: Unsupported Media Type
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
        '422':
          description: Validation Error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/HTTPValidationError'
  /experimental/ls/inference/chat_completion:
    post:
      summary: Llama Stack-compatible chat endpoint
      operationId: create_llama_stack_chat_completion_experimental_ls_inference_chat_completion_post
      parameters:
      - name: content-type
        in: header
        required: false
        schema:
          anyOf:
          - type: string
          - type: 'null'
          title: Content-Type
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ChatCompletionRequest'
      responses:
        '200':
          description: Successful Response
          content:
            application/json:
              schema:
                anyOf:
                - $ref: '#/components/schemas/nim_llm_sdk__entrypoints__llamastack__protocol__ChatCompletionResponse'
                - $ref: '#/components/schemas/ChatCompletionResponseStreamChunk'
                title: Response Create Llama Stack Chat Completion Experimental Ls
                  Inference Chat Completion Post
        '400':
          description: Received an invalid request possibly containing unsupported
            or out-of-range parameter values.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
        '404':
          description: The requested model does not exist.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
        '500':
          description: Internal Server Error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
        '415':
          description: Unsupported Media Type
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
        '422':
          description: Validation Error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/HTTPValidationError'
  /experimental/ls/inference/completion:
    post:
      summary: LlamaStack-compatible completion endpoint
      operationId: create_llama_stack_completion_experimental_ls_inference_completion_post
      parameters:
      - name: content-type
        in: header
        required: false
        schema:
          anyOf:
          - type: string
          - type: 'null'
          title: Content-Type
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CompletionRequest'
      responses:
        '200':
          description: Successful Response
          content:
            application/json:
              schema:
                anyOf:
                - $ref: '#/components/schemas/nim_llm_sdk__entrypoints__llamastack__protocol__CompletionResponse'
                - $ref: '#/components/schemas/CompletionResponseStreamChunk'
                title: Response Create Llama Stack Completion Experimental Ls Inference
                  Completion Post
        '400':
          description: Received an invalid request possibly containing unsupported
            or out-of-range parameter values.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
        '404':
          description: The requested model does not exist.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
        '500':
          description: Internal Server Error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
        '415':
          description: Unsupported Media Type
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
        '422':
          description: Validation Error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/HTTPValidationError'
  /v1/health/ready:
    get:
      summary: Health Ready
      operationId: health_ready_v1_health_ready_get
      responses:
        '200':
          description: Successful Response
          content:
            application/json:
              schema: {}
  /v1/health/live:
    get:
      summary: Health Live
      description: Handler for liveness endpoint.
      operationId: health_live_v1_health_live_get
      responses:
        '200':
          description: Successful Response
          content:
            application/json:
              schema: {}
  /v1/models:
    get:
      summary: List available models
      description: This endpoint will return a list of models available for inference.
        When the NIM is set up to serve customizations (e.g. LoRAs) this will also
        return the customizations available as models.
      operationId: show_available_models_v1_models_get
      responses:
        '200':
          description: Successful Response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ModelList'
  /v1/metadata:
    get:
      summary: Metadata
      description: Handler for metadata endpoint.
      operationId: metadata_v1_metadata_get
      responses:
        '200':
          description: Successful Response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/MetadataEndpointModel'
  /v1/version:
    get:
      summary: Returns version information about this NIM
      description: The `release` attribute corresponds to the product release version
        of the NIM. The `api` attribute is the openapi server API version running
        inside the NIM.
      operationId: show_version_v1_version_get
      responses:
        '200':
          description: Successful Response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/NIMLLMVersionResponse'
  /v1/metrics:
    get:
      summary: Metrics
      operationId: metrics_v1_metrics_get
      responses:
        '200':
          description: Successful Response
          content:
            application/json:
              schema:
                type: string
                title: Response Metrics V1 Metrics Get
  /v1/license:
    get:
      summary: License
      description: Handler for license endpoint.
      operationId: license_v1_license_get
      responses:
        '200':
          description: Successful Response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/LicenseEndpointModel'
  /v1/manifest:
    get:
      summary: Manifest
      description: Handler for the manifest endpoint.
      operationId: manifest_v1_manifest_get
      responses:
        '200':
          description: Successful Response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ManifestEndpointModel'
components:
  schemas:
    Attachment:
      properties:
        url:
          $ref: '#/components/schemas/URL'
        mime_type:
          type: string
          title: Mime Type
      type: object
      required:
      - url
      - mime_type
      title: Attachment
    BaseModel:
      properties: {}
      type: object
      title: BaseModel
    BuiltinTool:
      type: string
      enum:
      - brave_search
      - wolfram_alpha
      - photogen
      - code_interpreter
      title: BuiltinTool
    ChatCompletionLogProb:
      properties:
        token:
          type: string
          title: Token
        logprob:
          type: number
          title: Logprob
          default: -9999.0
        bytes:
          anyOf:
          - items:
              type: integer
            type: array
          - type: 'null'
          title: Bytes
      additionalProperties: false
      type: object
      required:
      - token
      title: ChatCompletionLogProb
    ChatCompletionLogProbs:
      properties:
        content:
          anyOf:
          - items:
              $ref: '#/components/schemas/ChatCompletionLogProbsContent'
            type: array
          - type: 'null'
          title: Content
      additionalProperties: false
      type: object
      title: ChatCompletionLogProbs
    ChatCompletionLogProbsContent:
      properties:
        token:
          type: string
          title: Token
        logprob:
          type: number
          title: Logprob
          default: -9999.0
        bytes:
          anyOf:
          - items:
              type: integer
            type: array
          - type: 'null'
          title: Bytes
        top_logprobs:
          items:
            $ref: '#/components/schemas/ChatCompletionLogProb'
          type: array
          title: Top Logprobs
      additionalProperties: false
      type: object
      required:
      - token
      title: ChatCompletionLogProbsContent
    ChatCompletionNamedFunction:
      properties:
        name:
          type: string
          title: Name
      additionalProperties: false
      type: object
      required:
      - name
      title: ChatCompletionNamedFunction
    ChatCompletionNamedToolChoiceParam:
      properties:
        function:
          $ref: '#/components/schemas/ChatCompletionNamedFunction'
        type:
          type: string
          const: function
          title: Type
          default: function
      additionalProperties: false
      type: object
      required:
      - function
      title: ChatCompletionNamedToolChoiceParam
    ChatCompletionRequest:
      properties:
        model:
          type: string
          title: Model
        messages:
          items:
            oneOf:
            - $ref: '#/components/schemas/UserMessage'
            - $ref: '#/components/schemas/SystemMessage'
            - $ref: '#/components/schemas/ToolResponseMessage'
            - $ref: '#/components/schemas/CompletionMessage-Input'
            discriminator:
              propertyName: role
              mapping:
                assistant: '#/components/schemas/CompletionMessage-Input'
                ipython: '#/components/schemas/ToolResponseMessage'
                system: '#/components/schemas/SystemMessage'
                user: '#/components/schemas/UserMessage'
          type: array
          title: Messages
        sampling_params:
          anyOf:
          - $ref: '#/components/schemas/SamplingParams'
          - type: 'null'
          default:
            strategy: greedy
            temperature: 0.0
            top_p: 0.95
            top_k: 0
            max_tokens: 0
            repetition_penalty: 1.0
        tools:
          anyOf:
          - items:
              $ref: '#/components/schemas/ToolDefinition'
            type: array
          - type: 'null'
          title: Tools
        tool_choice:
          anyOf:
          - type: string
            const: auto
          - type: string
            const: required
          - type: 'null'
          title: Tool Choice
        stream:
          anyOf:
          - type: boolean
          - type: 'null'
          title: Stream
          default: false
        logprobs:
          anyOf:
          - $ref: '#/components/schemas/LogProbConfig'
          - type: 'null'
      type: object
      required:
      - model
      - messages
      title: ChatCompletionRequest
    ChatCompletionResponseChoice:
      properties:
        index:
          type: integer
          title: Index
        message:
          $ref: '#/components/schemas/ChatMessage'
        logprobs:
          anyOf:
          - $ref: '#/components/schemas/ChatCompletionLogProbs'
          - type: 'null'
        finish_reason:
          anyOf:
          - type: string
            enum:
            - stop
            - length
            - tool_calls
          - type: 'null'
          title: Finish Reason
          default: stop
        stop_reason:
          anyOf:
          - type: integer
          - type: string
          - type: 'null'
          title: Stop Reason
      additionalProperties: false
      type: object
      required:
      - index
      - message
      title: ChatCompletionResponseChoice
    ChatCompletionResponseEvent:
      properties:
        event_type:
          $ref: '#/components/schemas/ChatCompletionResponseEventType'
        delta:
          anyOf:
          - type: string
          - $ref: '#/components/schemas/ToolCallDelta'
          title: Delta
        logprobs:
          anyOf:
          - items:
              $ref: '#/components/schemas/TokenLogProbs'
            type: array
          - type: 'null'
          title: Logprobs
        stop_reason:
          anyOf:
          - $ref: '#/components/schemas/StopReason'
          - type: 'null'
      type: object
      required:
      - event_type
      - delta
      title: ChatCompletionResponseEvent
      description: Chat completion response event.
    ChatCompletionResponseEventType:
      type: string
      enum:
      - start
      - complete
      - progress
      title: ChatCompletionResponseEventType
    ChatCompletionResponseStreamChoice:
      properties:
        index:
          type: integer
          title: Index
        delta:
          $ref: '#/components/schemas/DeltaMessage'
        logprobs:
          anyOf:
          - $ref: '#/components/schemas/ChatCompletionLogProbs'
          - type: 'null'
        finish_reason:
          anyOf:
          - type: string
            enum:
            - stop
            - length
            - tool_calls
          - type: 'null'
          title: Finish Reason
        stop_reason:
          anyOf:
          - type: integer
          - type: string
          - type: 'null'
          title: Stop Reason
      additionalProperties: false
      type: object
      required:
      - index
      - delta
      title: ChatCompletionResponseStreamChoice
    ChatCompletionResponseStreamChunk:
      properties:
        event:
          $ref: '#/components/schemas/ChatCompletionResponseEvent'
      type: object
      required:
      - event
      title: ChatCompletionResponseStreamChunk
      description: SSE-stream of these events.
    ChatCompletionStreamResponse:
      properties:
        id:
          type: string
          title: Id
        object:
          type: string
          const: chat.completion.chunk
          title: Object
          default: chat.completion.chunk
        created:
          type: integer
          title: Created
        model:
          type: string
          title: Model
        choices:
          items:
            $ref: '#/components/schemas/ChatCompletionResponseStreamChoice'
          type: array
          title: Choices
        usage:
          anyOf:
          - $ref: '#/components/schemas/UsageInfo'
          - type: 'null'
      additionalProperties: false
      type: object
      required:
      - model
      - choices
      title: ChatCompletionStreamResponse
    ChatCompletionToolsParam:
      properties:
        type:
          type: string
          const: function
          title: Type
          default: function
        function:
          $ref: '#/components/schemas/FunctionDefinition'
      additionalProperties: false
      type: object
      required:
      - function
      title: ChatCompletionToolsParam
    ChatMessage:
      properties:
        role:
          type: string
          title: Role
        content:
          anyOf:
          - type: string
          - type: 'null'
          title: Content
        tool_calls:
          anyOf:
          - items:
              $ref: '#/components/schemas/vllm__entrypoints__openai__protocol__ToolCall'
            type: array
          - type: 'null'
          title: Tool Calls
      additionalProperties: false
      type: object
      required:
      - role
      title: ChatMessage
    CompletionLogProbs:
      properties:
        text_offset:
          items:
            type: integer
          type: array
          title: Text Offset
        token_logprobs:
          items:
            anyOf:
            - type: number
            - type: 'null'
          type: array
          title: Token Logprobs
        tokens:
          items:
            type: string
          type: array
          title: Tokens
        top_logprobs:
          items:
            anyOf:
            - additionalProperties:
                type: number
              type: object
            - type: 'null'
          type: array
          title: Top Logprobs
      additionalProperties: false
      type: object
      title: CompletionLogProbs
    CompletionMessage-Input:
      properties:
        role:
          type: string
          const: assistant
          title: Role
          default: assistant
        content:
          anyOf:
          - type: string
          - $ref: '#/components/schemas/Attachment'
          - items:
              anyOf:
              - type: string
              - $ref: '#/components/schemas/Attachment'
            type: array
          title: Content
        stop_reason:
          $ref: '#/components/schemas/StopReason'
        tool_calls:
          items:
            $ref: '#/components/schemas/nim_llm_sdk__entrypoints__llamastack__protocol__ToolCall'
          type: array
          title: Tool Calls
      type: object
      required:
      - content
      - stop_reason
      title: CompletionMessage
    CompletionMessage-Output:
      properties:
        role:
          type: string
          const: assistant
          title: Role
          default: assistant
        content:
          anyOf:
          - type: string
          - $ref: '#/components/schemas/Attachment'
          - items:
              anyOf:
              - type: string
              - $ref: '#/components/schemas/Attachment'
            type: array
          title: Content
        stop_reason:
          $ref: '#/components/schemas/StopReason'
        tool_calls:
          items:
            $ref: '#/components/schemas/nim_llm_sdk__entrypoints__llamastack__protocol__ToolCall'
          type: array
          title: Tool Calls
      type: object
      required:
      - content
      - stop_reason
      title: CompletionMessage
    CompletionRequest:
      properties:
        model:
          type: string
          title: Model
        content:
          anyOf:
          - type: string
          - $ref: '#/components/schemas/Attachment'
          - items:
              anyOf:
              - type: string
              - $ref: '#/components/schemas/Attachment'
            type: array
          title: Content
        sampling_params:
          anyOf:
          - $ref: '#/components/schemas/SamplingParams'
          - type: 'null'
          default:
            strategy: greedy
            temperature: 0.0
            top_p: 0.95
            top_k: 0
            max_tokens: 0
            repetition_penalty: 1.0
        stream:
          anyOf:
          - type: boolean
          - type: 'null'
          title: Stream
          default: false
        logprobs:
          anyOf:
          - $ref: '#/components/schemas/LogProbConfig'
          - type: 'null'
      type: object
      required:
      - model
      - content
      title: CompletionRequest
    CompletionResponseChoice:
      properties:
        index:
          type: integer
          title: Index
        text:
          type: string
          title: Text
        logprobs:
          anyOf:
          - $ref: '#/components/schemas/CompletionLogProbs'
          - type: 'null'
        finish_reason:
          anyOf:
          - type: string
          - type: 'null'
          title: Finish Reason
        stop_reason:
          anyOf:
          - type: integer
          - type: string
          - type: 'null'
          title: Stop Reason
          description: The stop string or token id that caused the completion to stop,
            None if the completion finished for some other reason including encountering
            the EOS token
        prompt_logprobs:
          anyOf:
          - items:
              anyOf:
              - additionalProperties:
                  $ref: '#/components/schemas/Logprob'
                type: object
              - type: 'null'
            type: array
          - type: 'null'
          title: Prompt Logprobs
      additionalProperties: false
      type: object
      required:
      - index
      - text
      title: CompletionResponseChoice
    CompletionResponseStreamChoice:
      properties:
        index:
          type: integer
          title: Index
        text:
          type: string
          title: Text
        logprobs:
          anyOf:
          - $ref: '#/components/schemas/CompletionLogProbs'
          - type: 'null'
        finish_reason:
          anyOf:
          - type: string
          - type: 'null'
          title: Finish Reason
        stop_reason:
          anyOf:
          - type: integer
          - type: string
          - type: 'null'
          title: Stop Reason
          description: The stop string or token id that caused the completion to stop,
            None if the completion finished for some other reason including encountering
            the EOS token
      additionalProperties: false
      type: object
      required:
      - index
      - text
      title: CompletionResponseStreamChoice
    CompletionResponseStreamChunk:
      properties:
        delta:
          type: string
          title: Delta
        stop_reason:
          anyOf:
          - $ref: '#/components/schemas/StopReason'
          - type: 'null'
        logprobs:
          anyOf:
          - items:
              $ref: '#/components/schemas/TokenLogProbs'
            type: array
          - type: 'null'
          title: Logprobs
      type: object
      required:
      - delta
      title: CompletionResponseStreamChunk
      description: streamed completion response.
    CompletionStreamResponse:
      properties:
        id:
          type: string
          title: Id
        object:
          type: string
          title: Object
          default: text_completion
        created:
          type: integer
          title: Created
        model:
          type: string
          title: Model
        choices:
          items:
            $ref: '#/components/schemas/CompletionResponseStreamChoice'
          type: array
          title: Choices
        usage:
          anyOf:
          - $ref: '#/components/schemas/UsageInfo'
          - type: 'null'
      additionalProperties: false
      type: object
      required:
      - model
      - choices
      title: CompletionStreamResponse
    DeltaMessage:
      properties:
        role:
          anyOf:
          - type: string
          - type: 'null'
          title: Role
        content:
          anyOf:
          - type: string
          - type: 'null'
          title: Content
        tool_calls:
          anyOf:
          - items:
              $ref: '#/components/schemas/vllm__entrypoints__openai__protocol__ToolCall'
            type: array
          - type: 'null'
          title: Tool Calls
      additionalProperties: false
      type: object
      title: DeltaMessage
    ErrorResponse:
      properties:
        object:
          type: string
          title: Object
          default: error
        message:
          type: string
          title: Message
        type:
          type: string
          title: Type
        param:
          anyOf:
          - type: string
          - type: 'null'
          title: Param
        code:
          type: integer
          title: Code
      additionalProperties: false
      type: object
      required:
      - message
      - type
      - code
      title: ErrorResponse
    FunctionCall:
      properties:
        name:
          anyOf:
          - type: string
          - type: 'null'
          title: Name
          default: ''
        arguments:
          anyOf:
          - type: string
          - type: 'null'
          title: Arguments
          default: ''
      additionalProperties: false
      type: object
      title: FunctionCall
    FunctionDefinition:
      properties:
        name:
          type: string
          title: Name
        description:
          anyOf:
          - type: string
          - type: 'null'
          title: Description
        parameters:
          anyOf:
          - type: object
          - type: 'null'
          title: Parameters
      additionalProperties: false
      type: object
      required:
      - name
      title: FunctionDefinition
    HTTPValidationError:
      properties:
        detail:
          items:
            $ref: '#/components/schemas/ValidationError'
          type: array
          title: Detail
      type: object
      title: HTTPValidationError
    LicenseEndpointModel:
      properties:
        name:
          type: string
          title: Name
          description: The name of the license for the NIM container.
        path:
          type: string
          title: Path
          description: The filepath within the container containing the license content.
        sha:
          type: string
          title: Sha
          description: A SHA1 hash of the license contents.
        size:
          type: integer
          title: Size
          description: The number of characters in the license content.
        url:
          type: string
          title: Url
          description: The url where this license is hosted externally.
        type:
          type: string
          const: file
          title: Type
          description: The format of the license content.
        content:
          type: string
          title: Content
          description: The license text.
      type: object
      required:
      - name
      - path
      - sha
      - size
      - url
      - type
      - content
      title: LicenseEndpointModel
      description: A model representing the license response.
    LogProbConfig:
      properties:
        top_k:
          anyOf:
          - type: integer
          - type: 'null'
          title: Top K
          default: 0
      type: object
      title: LogProbConfig
    Logprob:
      properties:
        logprob:
          type: number
          title: Logprob
        rank:
          anyOf:
          - type: integer
          - type: 'null'
          title: Rank
        decoded_token:
          anyOf:
          - type: string
          - type: 'null'
          title: Decoded Token
      type: object
      required:
      - logprob
      title: Logprob
    ManifestEndpointModel:
      properties:
        manifest_file:
          type: string
          title: Manifest File
          description: The content of the manifest file describing the required model
            artifacts.
        repository_override:
          type: string
          title: Repository Override
          description: Alternate location used to retrieve artifacts from manifest
            file.
      type: object
      required:
      - manifest_file
      - repository_override
      title: ManifestEndpointModel
      description: A model representing the manifest response.
    MetadataEndpointModel:
      properties:
        assetInfo:
          items:
            type: string
          type: array
          title: Assetinfo
          description: A list of required container assets excluding model artifacts
        licenseInfo:
          $ref: '#/components/schemas/LicenseEndpointModel'
          description: The license info.
        modelInfo:
          items:
            $ref: '#/components/schemas/ModelInfo'
          type: array
          title: Modelinfo
          description: A list of models being served by the NIM.
        repository_override:
          type: string
          title: Repository Override
          description: Alternate location used to retrieve artifacts from manifest
            file.
        version:
          type: string
          title: Version
          description: The version of the NIM service.
      type: object
      required:
      - assetInfo
      - licenseInfo
      - modelInfo
      - repository_override
      - version
      title: MetadataEndpointModel
      description: A model representing the metadata response.
    ModelCard:
      properties:
        id:
          type: string
          title: Id
        object:
          type: string
          title: Object
          default: model
        created:
          type: integer
          title: Created
        owned_by:
          type: string
          title: Owned By
          default: vllm
        root:
          anyOf:
          - type: string
          - type: 'null'
          title: Root
        parent:
          anyOf:
          - type: string
          - type: 'null'
          title: Parent
        max_model_len:
          anyOf:
          - type: integer
          - type: 'null'
          title: Max Model Len
        permission:
          items:
            $ref: '#/components/schemas/ModelPermission'
          type: array
          title: Permission
      additionalProperties: false
      type: object
      required:
      - id
      title: ModelCard
    ModelInfo:
      properties:
        modelUrl:
          type: string
          title: Modelurl
        shortName:
          type: string
          title: Shortname
      type: object
      required:
      - modelUrl
      - shortName
      title: ModelInfo
      description: A model representing the model response.
    ModelList:
      properties:
        object:
          type: string
          title: Object
          default: list
        data:
          items:
            $ref: '#/components/schemas/ModelCard'
          type: array
          title: Data
      additionalProperties: false
      type: object
      title: ModelList
    ModelPermission:
      properties:
        id:
          type: string
          title: Id
        object:
          type: string
          title: Object
          default: model_permission
        created:
          type: integer
          title: Created
        allow_create_engine:
          type: boolean
          title: Allow Create Engine
          default: false
        allow_sampling:
          type: boolean
          title: Allow Sampling
          default: true
        allow_logprobs:
          type: boolean
          title: Allow Logprobs
          default: true
        allow_search_indices:
          type: boolean
          title: Allow Search Indices
          default: false
        allow_view:
          type: boolean
          title: Allow View
          default: true
        allow_fine_tuning:
          type: boolean
          title: Allow Fine Tuning
          default: false
        organization:
          type: string
          title: Organization
          default: '*'
        group:
          anyOf:
          - type: string
          - type: 'null'
          title: Group
        is_blocking:
          type: boolean
          title: Is Blocking
          default: false
      additionalProperties: false
      type: object
      title: ModelPermission
    NIMAssetInfoResponse:
      properties:
        assetName:
          type: string
          title: Assetname
          description: The name of the asset used by NIMs.
        url:
          type: string
          title: Url
          description: The url of the asset being used.
        checksum:
          type: string
          title: Checksum
          description: The unique identifier for asset.
      type: object
      required:
      - assetName
      - url
      - checksum
      title: NIMAssetInfoResponse
    NIMHealthSuccessResponse:
      properties:
        object:
          type: string
          title: Object
          default: health.response
        message:
          type: string
          title: Message
      type: object
      required:
      - message
      title: NIMHealthSuccessResponse
    NIMLLMChatCompletionMessage:
      properties:
        role:
          $ref: '#/components/schemas/Role'
          description: The role of the message's author.
        content:
          anyOf:
          - type: string
            minLength: 1
          - type: 'null'
          title: Content
          description: The contents of the message. For a reward model, the predicted
            attributes, i.e. reward scores, will be returned.
        tool_call_id:
          anyOf:
          - type: string
          - type: 'null'
          title: Tool Call Id
          description: The id of the tool call.
        name:
          anyOf:
          - type: string
          - type: 'null'
          title: Name
          description: The name of the tool called.
        tool_calls:
          anyOf:
          - items:
              $ref: '#/components/schemas/vllm__entrypoints__openai__protocol__ToolCall'
            type: array
          - type: 'null'
          title: Tool Calls
          description: The tool(s) called by the model.
      type: object
      required:
      - role
      title: NIMLLMChatCompletionMessage
    NIMLLMChatCompletionRequest:
      properties:
        messages:
          items:
            $ref: '#/components/schemas/NIMLLMChatCompletionMessage'
          type: array
          minItems: 1
          title: Messages
          description: A list of messages comprising the conversation so far.
        model:
          type: string
          title: Model
          description: The model to use.
        frequency_penalty:
          anyOf:
          - type: number
            maximum: 2.0
            minimum: -2.0
          - type: 'null'
          title: Frequency Penalty
          description: Number between -2.0 and 2.0. Positive values penalize new tokens
            based on their existing frequency in the text so far, decreasing the model's
            likelihood to repeat the same line verbatim.
          default: 0.0
        logit_bias:
          anyOf:
          - additionalProperties:
              type: number
            type: object
          - type: 'null'
          title: Logit Bias
          description: Modify the likelihood of specified tokens appearing in the
            completion. Accepts a JSON object that maps tokens (specified by their
            token ID in the tokenizer) to an associated bias value from -100 to 100.
            Mathematically, the bias is added to the logits generated by the model
            prior to sampling. The exact effect will vary per model, but values between
            -1 and 1 should decrease or increase likelihood of selection; values like
            -100 or 100 should result in a ban or exclusive selection of the relevant
            token.
        logprobs:
          anyOf:
          - type: boolean
          - type: 'null'
          title: Logprobs
          description: Whether to return log probabilities of the output tokens or
            not. If true, returns the log probabilities of each output token returned
            in the `content` of `message`.
          default: false
        top_logprobs:
          anyOf:
          - type: integer
            maximum: 20.0
            minimum: 1.0
          - type: 'null'
          title: Top Logprobs
          description: An integer specifying the number of most likely tokens to return
            at each token position, each with an associated log probability. `logprobs`
            must be set to `true` if this parameter is used.
        max_tokens:
          anyOf:
          - type: integer
            minimum: 1.0
          - type: 'null'
          title: Max Tokens
          description: The maximum number of tokens that can be generated.
        n:
          anyOf:
          - type: integer
            maximum: 128.0
            minimum: 1.0
          - type: 'null'
          title: N
          description: How many completions to generate for each prompt.
          default: 1
        presence_penalty:
          anyOf:
          - type: number
            maximum: 2.0
            minimum: -2.0
          - type: 'null'
          title: Presence Penalty
          description: Number between -2.0 and 2.0. Positive values penalize new tokens
            based on whether they appear in the text so far, increasing the model's
            likelihood to talk about new topics.
          default: 0.0
        response_format:
          anyOf:
          - $ref: '#/components/schemas/ResponseFormat'
          - type: 'null'
          description: 'An object specifying the format that the model must output.
            Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees
            the message the model generates is valid JSON.'
        seed:
          anyOf:
          - type: integer
            maximum: 9.223372036854776e+18
            minimum: -9.223372036854776e+18
          - type: 'null'
          title: Seed
          description: Changing the seed will produce a different response with similar
            characteristics. Fixing the seed will reproduce the same results if all
            other parameters are also kept constant.
        stop:
          anyOf:
          - items:
              type: string
            type: array
          - type: string
          - type: 'null'
          title: Stop
          description: Sequences where the API will stop generating further tokens.
        stream:
          anyOf:
          - type: boolean
          - type: 'null'
          title: Stream
          description: 'If set, partial message deltas will be sent, like in ChatGPT.
            Tokens will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)
            as they become available, with the stream terminated by a `data: [DONE]`'
          default: false
        stream_options:
          anyOf:
          - $ref: '#/components/schemas/StreamOptions'
          - type: 'null'
        temperature:
          anyOf:
          - type: number
            maximum: 2.0
            minimum: 0.0
          - type: 'null'
          title: Temperature
          description: What sampling temperature to use, between 0 and 2. Higher values
            like 0.8 will make the output more random, while lower values like 0.2
            will make it more focused and deterministic.
          default: 1.0
        top_p:
          anyOf:
          - type: number
            maximum: 1.0
            exclusiveMinimum: 0.0
          - type: 'null'
          title: Top P
          description: An alternative to sampling with temperature, called nucleus
            sampling, where the model considers the results of the tokens with top_p
            probability mass. So 0.1 means only the tokens comprising the top 10%
            probability mass are considered. We generally recommend altering this
            or `temperature` but not both.
          default: 1.0
        tools:
          anyOf:
          - items:
              $ref: '#/components/schemas/ChatCompletionToolsParam'
            type: array
          - type: 'null'
          title: Tools
        tool_choice:
          anyOf:
          - type: string
            enum:
            - none
            - auto
            - required
          - $ref: '#/components/schemas/ChatCompletionNamedToolChoiceParam'
          - type: 'null'
          title: Tool Choice
          description: Controls which (if any) tool is called by the model.
          default: none
        parallel_tool_calls:
          anyOf:
          - type: boolean
          - type: 'null'
          title: Parallel Tool Calls
          default: true
        user:
          anyOf:
          - type: string
            minLength: 1
          - type: 'null'
          title: User
          description: A unique identifier representing your end-user.
        min_p:
          type: number
          title: Min P
          default: 0.0
        prompt_logprobs:
          anyOf:
          - type: integer
          - type: 'null'
          title: Prompt Logprobs
        add_special_tokens:
          type: boolean
          title: Add Special Tokens
          description: If true, special tokens (e.g. BOS) will be added to the prompt
            on top of what is added by the chat template. For most models, the chat
            template takes care of adding the special tokens so this should be set
            to false (as is the default).
          default: false
        documents:
          anyOf:
          - items:
              additionalProperties:
                type: string
              type: object
            type: array
          - type: 'null'
          title: Documents
          description: A list of dicts representing documents that will be accessible
            to the model if it is performing RAG (retrieval-augmented generation).
            If the template does not support RAG, this argument will have no effect.
            We recommend that each document should be a dict containing "title" and
            "text" keys.
        chat_template:
          anyOf:
          - type: string
          - type: 'null'
          title: Chat Template
          description: A Jinja template to use for this conversion. As of transformers
            v4.44, default chat template is no longer allowed, so you must provide
            a chat template if the tokenizer does not define one.
        chat_template_kwargs:
          anyOf:
          - type: object
          - type: 'null'
          title: Chat Template Kwargs
          description: Additional kwargs to pass to the template renderer. Will be
            accessible by the chat template.
        guided_whitespace_pattern:
          anyOf:
          - type: string
          - type: 'null'
          title: Guided Whitespace Pattern
          description: If specified, will override the default whitespace pattern
            for guided json decoding.
        nvext:
          anyOf:
          - $ref: '#/components/schemas/NVExt'
          - type: 'null'
          description: Extension dictionary for NIM API.
      additionalProperties: false
      type: object
      required:
      - messages
      - model
      title: NIMLLMChatCompletionRequest
    NIMLLMCompletionRequest:
      properties:
        model:
          type: string
          title: Model
          description: The model to use.
        prompt:
          anyOf:
          - items:
              type: integer
            type: array
          - items:
              items:
                type: integer
              type: array
            type: array
          - type: string
            minLength: 1
          - items:
              type: string
              minLength: 1
            type: array
          minLength: 1
          title: Prompt
        echo:
          anyOf:
          - type: boolean
          - type: 'null'
          title: Echo
          description: If true, echo back the prompt in addition to the completion.
            'echo' and 'stream' fields cannot be true simultaneously.
          default: false
        frequency_penalty:
          anyOf:
          - type: number
            maximum: 2.0
            minimum: -2.0
          - type: 'null'
          title: Frequency Penalty
          description: Number between -2.0 and 2.0. Positive values penalize new tokens
            based on their existing frequency in the text so far, decreasing the model's
            likelihood to repeat the same line verbatim.
          default: 0.0
        logit_bias:
          anyOf:
          - additionalProperties:
              type: number
            type: object
          - type: 'null'
          title: Logit Bias
          description: Modify the likelihood of specified tokens appearing in the
            completion. Accepts a JSON object that maps tokens (specified by their
            token ID in the tokenizer) to an associated bias value from -100 to 100.
            Mathematically, the bias is added to the logits generated by the model
            prior to sampling. The exact effect will vary per model, but values between
            -1 and 1 should decrease or increase likelihood of selection; values like
            -100 or 100 should result in a ban or exclusive selection of the relevant
            token.
        logprobs:
          anyOf:
          - type: integer
            maximum: 5.0
            minimum: 0.0
          - type: 'null'
          title: Logprobs
          description: Include the log probabilities on the `logprobs` most likely
            output tokens, as well the chosen tokens. For example, if `logprobs` is
            5, the API will return a list of the 5 most likely tokens. The API will
            always return the `logprob` of the sampled token, so there may be up to
            `logprobs+1` elements in the response.
        max_tokens:
          anyOf:
          - type: integer
            minimum: 1.0
          - type: 'null'
          title: Max Tokens
          description: The maximum number of tokens that can be generated.
          default: 16
        n:
          anyOf:
          - type: integer
            maximum: 128.0
            minimum: 1.0
          - type: 'null'
          title: N
          description: How many completions to generate for each prompt.
          default: 1
        presence_penalty:
          anyOf:
          - type: number
            maximum: 2.0
            minimum: -2.0
          - type: 'null'
          title: Presence Penalty
          description: Number between -2.0 and 2.0. Positive values penalize new tokens
            based on whether they appear in the text so far, increasing the model's
            likelihood to talk about new topics.
          default: 0.0
        seed:
          anyOf:
          - type: integer
            maximum: 9.223372036854776e+18
            minimum: -9.223372036854776e+18
          - type: 'null'
          title: Seed
          description: Changing the seed will produce a different response with similar
            characteristics. Fixing the seed will reproduce the same results if all
            other parameters are also kept constant.
        stop:
          anyOf:
          - items:
              type: string
            type: array
          - type: string
          - type: 'null'
          title: Stop
          description: Sequences where the API will stop generating further tokens.
        stream:
          anyOf:
          - type: boolean
          - type: 'null'
          title: Stream
          description: 'If set, partial message deltas will be sent, like in ChatGPT.
            Tokens will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)
            as they become available, with the stream terminated by a `data: [DONE]`'
          default: false
        stream_options:
          anyOf:
          - $ref: '#/components/schemas/StreamOptions'
          - type: 'null'
        suffix:
          anyOf:
          - type: string
          - type: 'null'
          title: Suffix
          description: The suffix that comes after a completion of inserted text.
        temperature:
          anyOf:
          - type: number
            maximum: 2.0
            minimum: 0.0
          - type: 'null'
          title: Temperature
          description: What sampling temperature to use, between 0 and 2. Higher values
            like 0.8 will make the output more random, while lower values like 0.2
            will make it more focused and deterministic.
          default: 1.0
        top_p:
          anyOf:
          - type: number
            maximum: 1.0
            exclusiveMinimum: 0.0
          - type: 'null'
          title: Top P
          description: An alternative to sampling with temperature, called nucleus
            sampling, where the model considers the results of the tokens with top_p
            probability mass. So 0.1 means only the tokens comprising the top 10%
            probability mass are considered. We generally recommend altering this
            or `temperature` but not both.
          default: 1.0
        user:
          anyOf:
          - type: string
            minLength: 1
          - type: 'null'
          title: User
          description: A unique identifier representing your end-user.
        min_p:
          type: number
          title: Min P
          default: 0.0
        prompt_logprobs:
          anyOf:
          - type: integer
          - type: 'null'
          title: Prompt Logprobs
        add_special_tokens:
          type: boolean
          title: Add Special Tokens
          description: If true (the default), special tokens (e.g. BOS) will be added
            to the prompt.
          default: true
        response_format:
          anyOf:
          - $ref: '#/components/schemas/ResponseFormat'
          - type: 'null'
          description: 'An object specifying the format that the model must output.
            Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees
            the message the model generates is valid JSON.'
        guided_whitespace_pattern:
          anyOf:
          - type: string
          - type: 'null'
          title: Guided Whitespace Pattern
          description: If specified, will override the default whitespace pattern
            for guided json decoding. Must be used with guided_json. Supported in
            'fast_outlines' and 'outlines' backends.
        nvext:
          anyOf:
          - $ref: '#/components/schemas/NVExt'
          - type: 'null'
          description: Extension dictionary for NIM API.
      additionalProperties: false
      type: object
      required:
      - model
      - prompt
      title: NIMLLMCompletionRequest
    NIMLLMVersionResponse:
      properties:
        release:
          type: string
          title: Release
          description: The product release version of NIM for LLMs.
        api:
          type: string
          title: Api
          description: The server API version running inside the NIM.
      type: object
      required:
      - release
      - api
      title: NIMLLMVersionResponse
    NIMLicenseInfoResponse:
      properties:
        name:
          type: string
          title: Name
          description: The name of the NIMs license.
        path:
          type: string
          title: Path
          description: The path of the NIMs license file inside the container.
        sha:
          type: string
          title: Sha
          description: The unique identifier of the license.
        size:
          type: integer
          title: Size
          description: The size of the license file in bytes.
        url:
          type: string
          title: Url
          description: The url of the NIMs license.
        type:
          type: string
          title: Type
          description: The content type of the license.
        content:
          type: string
          title: Content
          description: The content inside the NIMs license file.
      type: object
      required:
      - name
      - path
      - sha
      - size
      - url
      - type
      - content
      title: NIMLicenseInfoResponse
    NIMMetadataResponse:
      properties:
        version:
          $ref: '#/components/schemas/NIMLLMVersionResponse'
          description: The product release version information of NIM for LLMs
        modelInfo:
          items:
            $ref: '#/components/schemas/NIMModelInfoResponse'
          type: array
          title: Modelinfo
          description: The list of information of models being served inside NIMs
            container
          default: []
        assetInfo:
          items:
            $ref: '#/components/schemas/NIMAssetInfoResponse'
          type: array
          title: Assetinfo
          description: The list of different assets used by the NIMs
          default: []
        licenseInfo:
          $ref: '#/components/schemas/NIMLicenseInfoResponse'
          description: The information of the license of released NIMs
      type: object
      required:
      - version
      - licenseInfo
      title: NIMMetadataResponse
    NIMModelInfoResponse:
      properties:
        shortName:
          type: string
          title: Shortname
          description: The name of the model served by NIMs
        modelUrl:
          type: string
          title: Modelurl
          description: The URL from which the model is downloaded.
      type: object
      required:
      - shortName
      - modelUrl
      title: NIMModelInfoResponse
    NVExt:
      properties:
        ignore_eos:
          anyOf:
          - type: boolean
          - type: 'null'
          title: Ignore Eos
          description: Whether to ignore End of Sequence (EOS) tokens. It is advised
            to set max_tokens when this is set to avoid overly long response times.
        repetition_penalty:
          anyOf:
          - type: number
            maximum: 2.0
            exclusiveMinimum: 0.0
          - type: 'null'
          title: Repetition Penalty
          description: How much to penalize tokens based on how frequently they occur
            in the text. A value of 1 means no penalty, while values larger than 1
            discourage and values smaller encourage.
          default: 1.0
        top_k:
          type: integer
          minimum: -1.0
          title: Top K
          description: How many of the top tokens to sample from. Must be -1 or greater
            than or equal to 1, and cannot be null. If not set, then the default is
            -1 which disables top_k sampling (greedy).
          default: -1
        guided_choice:
          anyOf:
          - items:
              type: string
            type: array
          - type: 'null'
          title: Guided Choice
          description: If specified, the output will be exactly one of the choices.
        guided_json:
          anyOf:
          - type: string
          - type: object
          - $ref: '#/components/schemas/BaseModel'
          - type: 'null'
          title: Guided Json
          description: If specified, the output will follow the JSON schema. Can be
            a string, an object, a reference to a BaseModel, or null.
        guided_regex:
          anyOf:
          - type: string
          - type: 'null'
          title: Guided Regex
          description: If specified, the output will follow the regex pattern. Can
            be a string or null.
        guided_grammar:
          anyOf:
          - type: string
          - type: 'null'
          title: Guided Grammar
          description: If specified, the output will follow the context-free grammar.
            Can be a string or null.
        guided_decoding_backend:
          anyOf:
          - type: string
          - type: 'null'
          title: Guided Decoding Backend
          description: If specified, will override the default guided decoding backend
            of the server for this specific request. If set, must be one of 'outlines'
            / 'lm-format-enforcer' / named of a custom decoding backend
      type: object
      title: NVExt
    ResponseFormat:
      properties:
        type:
          type: string
          enum:
          - text
          - json_object
          title: Type
          description: Must be one of `text` or `json_object`.
          example: json_object
      type: object
      required:
      - type
      title: ResponseFormat
    Role:
      type: string
      enum:
      - assistant
      - user
      - system
      - tool
      - function
      title: Role
    SamplingParams:
      properties:
        strategy:
          $ref: '#/components/schemas/SamplingStrategy'
          default: greedy
        temperature:
          anyOf:
          - type: number
          - type: 'null'
          title: Temperature
          default: 0.0
        top_p:
          anyOf:
          - type: number
          - type: 'null'
          title: Top P
          default: 0.95
        top_k:
          anyOf:
          - type: integer
          - type: 'null'
          title: Top K
          default: 0
        max_tokens:
          anyOf:
          - type: integer
          - type: 'null'
          title: Max Tokens
          default: 0
        repetition_penalty:
          anyOf:
          - type: number
          - type: 'null'
          title: Repetition Penalty
          default: 1.0
      type: object
      title: SamplingParams
    SamplingStrategy:
      type: string
      enum:
      - greedy
      - top_p
      - top_k
      title: SamplingStrategy
    StopReason:
      type: string
      enum:
      - end_of_turn
      - end_of_message
      - out_of_tokens
      title: StopReason
    StreamOptions:
      properties:
        include_usage:
          anyOf:
          - type: boolean
          - type: 'null'
          title: Include Usage
          default: true
        continuous_usage_stats:
          anyOf:
          - type: boolean
          - type: 'null'
          title: Continuous Usage Stats
          default: true
      additionalProperties: false
      type: object
      title: StreamOptions
    SystemMessage:
      properties:
        role:
          type: string
          const: system
          title: Role
          default: system
        content:
          anyOf:
          - type: string
          - $ref: '#/components/schemas/Attachment'
          - items:
              anyOf:
              - type: string
              - $ref: '#/components/schemas/Attachment'
            type: array
          title: Content
      type: object
      required:
      - content
      title: SystemMessage
    TokenLogProbs:
      properties:
        logprobs_by_token:
          additionalProperties:
            type: number
          type: object
          title: Logprobs By Token
      type: object
      required:
      - logprobs_by_token
      title: TokenLogProbs
    ToolCallDelta:
      properties:
        content:
          anyOf:
          - type: string
          - $ref: '#/components/schemas/nim_llm_sdk__entrypoints__llamastack__protocol__ToolCall'
          title: Content
        parse_status:
          $ref: '#/components/schemas/ToolCallParseStatus'
      type: object
      required:
      - content
      - parse_status
      title: ToolCallDelta
    ToolCallParseStatus:
      type: string
      enum:
      - start
      - in_progress
      - failure
      - success
      title: ToolCallParseStatus
    ToolDefinition:
      properties:
        tool_name:
          anyOf:
          - $ref: '#/components/schemas/BuiltinTool'
          - type: string
          title: Tool Name
        description:
          anyOf:
          - type: string
          - type: 'null'
          title: Description
        parameters:
          anyOf:
          - additionalProperties:
              $ref: '#/components/schemas/ToolParamDefinition'
            type: object
          - type: 'null'
          title: Parameters
      type: object
      required:
      - tool_name
      title: ToolDefinition
    ToolParamDefinition:
      properties:
        param_type:
          type: string
          title: Param Type
        description:
          anyOf:
          - type: string
          - type: 'null'
          title: Description
        required:
          anyOf:
          - type: boolean
          - type: 'null'
          title: Required
          default: true
      type: object
      required:
      - param_type
      title: ToolParamDefinition
    ToolResponseMessage:
      properties:
        role:
          type: string
          const: ipython
          title: Role
          default: ipython
        call_id:
          type: string
          title: Call Id
        tool_name:
          anyOf:
          - $ref: '#/components/schemas/BuiltinTool'
          - type: string
          title: Tool Name
        content:
          anyOf:
          - type: string
          - $ref: '#/components/schemas/Attachment'
          - items:
              anyOf:
              - type: string
              - $ref: '#/components/schemas/Attachment'
            type: array
          title: Content
      type: object
      required:
      - call_id
      - tool_name
      - content
      title: ToolResponseMessage
    URL:
      properties:
        uri:
          type: string
          title: Uri
      type: object
      required:
      - uri
      title: URL
    UsageInfo:
      properties:
        prompt_tokens:
          type: integer
          title: Prompt Tokens
          default: 0
        total_tokens:
          type: integer
          title: Total Tokens
          default: 0
        completion_tokens:
          anyOf:
          - type: integer
          - type: 'null'
          title: Completion Tokens
          default: 0
      additionalProperties: false
      type: object
      title: UsageInfo
    UserMessage:
      properties:
        role:
          type: string
          const: user
          title: Role
          default: user
        content:
          anyOf:
          - type: string
          - $ref: '#/components/schemas/Attachment'
          - items:
              anyOf:
              - type: string
              - $ref: '#/components/schemas/Attachment'
            type: array
          title: Content
      type: object
      required:
      - content
      title: UserMessage
    ValidationError:
      properties:
        loc:
          items:
            anyOf:
            - type: string
            - type: integer
          type: array
          title: Location
        msg:
          type: string
          title: Message
        type:
          type: string
          title: Error Type
      type: object
      required:
      - loc
      - msg
      - type
      title: ValidationError
    nim_llm_sdk__entrypoints__llamastack__protocol__ChatCompletionResponse:
      properties:
        completion_message:
          $ref: '#/components/schemas/CompletionMessage-Output'
        logprobs:
          anyOf:
          - items:
              $ref: '#/components/schemas/TokenLogProbs'
            type: array
          - type: 'null'
          title: Logprobs
      type: object
      required:
      - completion_message
      title: ChatCompletionResponse
    nim_llm_sdk__entrypoints__llamastack__protocol__CompletionResponse:
      properties:
        completion_message:
          $ref: '#/components/schemas/CompletionMessage-Output'
        logprobs:
          anyOf:
          - items:
              $ref: '#/components/schemas/TokenLogProbs'
            type: array
          - type: 'null'
          title: Logprobs
      type: object
      required:
      - completion_message
      title: CompletionResponse
    nim_llm_sdk__entrypoints__llamastack__protocol__ToolCall:
      properties:
        call_id:
          type: string
          title: Call Id
        tool_name:
          anyOf:
          - $ref: '#/components/schemas/BuiltinTool'
          - type: string
          title: Tool Name
        arguments:
          anyOf:
          - additionalProperties:
              anyOf:
              - type: string
              - type: integer
              - type: number
              - type: boolean
              - items:
                  anyOf:
                  - type: string
                  - type: integer
                  - type: number
                  - type: boolean
                  - type: 'null'
                type: array
              - additionalProperties:
                  anyOf:
                  - type: string
                  - type: integer
                  - type: number
                  - type: boolean
                  - type: 'null'
                type: object
              - type: 'null'
            type: object
          - type: 'null'
          title: Arguments
      type: object
      required:
      - tool_name
      title: ToolCall
    vllm__entrypoints__openai__protocol__ChatCompletionResponse:
      properties:
        id:
          type: string
          title: Id
        object:
          type: string
          const: chat.completion
          title: Object
          default: chat.completion
        created:
          type: integer
          title: Created
        model:
          type: string
          title: Model
        choices:
          items:
            $ref: '#/components/schemas/ChatCompletionResponseChoice'
          type: array
          title: Choices
        usage:
          $ref: '#/components/schemas/UsageInfo'
        prompt_logprobs:
          anyOf:
          - items:
              anyOf:
              - additionalProperties:
                  $ref: '#/components/schemas/Logprob'
                type: object
              - type: 'null'
            type: array
          - type: 'null'
          title: Prompt Logprobs
      additionalProperties: false
      type: object
      required:
      - model
      - choices
      - usage
      title: ChatCompletionResponse
    vllm__entrypoints__openai__protocol__CompletionResponse:
      properties:
        id:
          type: string
          title: Id
        object:
          type: string
          title: Object
          default: text_completion
        created:
          type: integer
          title: Created
        model:
          type: string
          title: Model
        choices:
          items:
            $ref: '#/components/schemas/CompletionResponseChoice'
          type: array
          title: Choices
        usage:
          $ref: '#/components/schemas/UsageInfo'
      additionalProperties: false
      type: object
      required:
      - model
      - choices
      - usage
      title: CompletionResponse
    vllm__entrypoints__openai__protocol__ToolCall:
      properties:
        index:
          anyOf:
          - type: integer
          - type: 'null'
          title: Index
        id:
          type: string
          title: Id
        type:
          type: string
          const: function
          title: Type
          default: function
        function:
          $ref: '#/components/schemas/FunctionCall'
      additionalProperties: false
      type: object
      required:
      - function
      title: ToolCall
