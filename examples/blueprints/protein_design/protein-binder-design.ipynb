{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# De Novo Protein Design Workflow using NIMs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example notebook outlines a workflow for creating de novo protein binders using NVIDIA Inference Microservices (NIMs). This workflow leverages advanced AI models to enable computational biologists to design novel protein structures efficiently.\n",
    "\n",
    "The input to this workflow is a protein sequence, which is then fed to AlphaFold2 for structural prediction; alternatively, this can be skipped and a precomputed protein structure (in PDB format) can be used as input. Protein backbones are then generated with RFDiffusion, sequences are generated with ProteinMPNN, and finally complex structures are predicted with AlphaFold2-multimer. \n",
    "\n",
    "This setup provides a powerful framework for exploring protein design, offering flexibility and precision in generating functional protein binders. For more information, refer to the respective repositories and documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting started with NIMs\n",
    "\n",
    "Navigate to the `deploy` directory and follow the instructions in the `README.md` to run docker compose:\n",
    "\n",
    "```bash\n",
    "docker compose up\n",
    "```\n",
    "Download of the AlphaFold NIM data is time consuming and requires roughly 1.2TB of disk space\n",
    "\n",
    "After set up is complete, check the status of the four running NIMS e.g with the command:\n",
    "\n",
    "```bash\n",
    "curl localhost:8081/v1/health/ready\n",
    "curl localhost:8082/v1/health/ready\n",
    "curl localhost:8083/v1/health/ready\n",
    "curl localhost:8084/v1/health/ready\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll install some prerequisites so our examples work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import requests\n",
    "from enum import StrEnum, Enum\n",
    "from typing import Tuple, Dict, Any, List\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll need to start up the NIMs. While this will return quickly, it will take some time for the models to download (roughly 3-6 hours on a 1000mbps internet connection)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One needs to use an NGC Personal Key to run the examples below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NVIDIA_API_KEY = os.getenv(\"NVIDIA_API_KEY\") or input(\"Paste Run Key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEADERS = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {NVIDIA_API_KEY}\",\n",
    "    \"poll-seconds\": \"900\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NIM_HOST_URL_BASE = \"http://localhost\"\n",
    "\n",
    "class NIM_PORTS(Enum):\n",
    "    ALPHAFOLD2_PORT = 8081\n",
    "    RFDIFFUSION_PORT = 8082\n",
    "    PROTEINMPNN_PORT = 8083\n",
    "    AF2_MULTIMER_PORT = 8084\n",
    "\n",
    "\n",
    "class NIM_ENDPOINTS(StrEnum):\n",
    "    ALPHAFOLD2 = \"protein-structure/alphafold2/predict-structure-from-sequence\"\n",
    "    RFDIFFUSION =  \"biology/ipd/rfdiffusion/generate\"\n",
    "    PROTEINMPNN =  \"biology/ipd/proteinmpnn/predict\"\n",
    "    AF2_MULTIMER = \"protein-structure/alphafold2/multimer/predict-structure-from-sequences\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_nim(\n",
    "            payload: Dict[str, Any],\n",
    "            nim_endpoint: str,\n",
    "            headers: Dict[str, str] = HEADERS,\n",
    "            base_url: str = \"http://localhost\",\n",
    "            nim_port: int = 8080,\n",
    "            echo: bool = False) -> Tuple[int, Dict]:\n",
    "    function_url = f\"{base_url}:{nim_port}/{nim_endpoint}\"\n",
    "    if echo:\n",
    "        print(\"*\"*80)\n",
    "        print(f\"\\tURL: {function_url}\")\n",
    "        print(f\"\\tPayload: {payload}\")\n",
    "        print(\"*\"*80)\n",
    "    response = requests.post(function_url,\n",
    "                            json=payload,\n",
    "                            headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        return response.status_code, response.json()\n",
    "    else:\n",
    "        raise Exception(f\"Error: response returned code [{response.status_code}], with text: {response.text}\")\n",
    "\n",
    "def check_nim_readiness(nim_port: NIM_PORTS,\n",
    "                        base_url: str = NIM_HOST_URL_BASE,\n",
    "                        endpoint: str = \"v1/health/ready\") -> bool:\n",
    "    \"\"\"\n",
    "    Return true if a NIM is ready.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(f\"{base_url}:{nim_port}/{endpoint}\")\n",
    "        d = response.json()\n",
    "        if \"status\" in d:\n",
    "            if d[\"status\"] == \"ready\":\n",
    "                return True\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return False\n",
    "\n",
    "def get_reduced_pdb(pdb_id: str, rcsb_path: str = None) -> str:\n",
    "    pdb = Path(pdb_id)\n",
    "    if not pdb.exists() and rcsb_path is not None:\n",
    "        pdb.write_text(requests.get(rcsb_path).text)\n",
    "    lines = filter(lambda line: line.startswith(\"ATOM\"), pdb.read_text().split(\"\\n\"))\n",
    "    return \"\\n\".join(list(lines))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleRequestParams:\n",
    "    def __init__(self,\n",
    "                target_sequence: str,\n",
    "                contigs: str, \n",
    "                hotspot_res: List[str],\n",
    "                input_pdb_chains: List[str],\n",
    "                ca_only: bool,\n",
    "                use_soluble_model: bool,\n",
    "                sampling_temp: List[float],\n",
    "                diffusion_steps: int = 15,\n",
    "                num_seq_per_target: int = 20):\n",
    "        self.target_sequence = target_sequence\n",
    "        self.contigs = contigs\n",
    "        self.hotspot_res = hotspot_res\n",
    "        self.input_pdb_chains = input_pdb_chains\n",
    "        self.ca_only = ca_only\n",
    "        self.use_soluble_model = use_soluble_model\n",
    "        self.sampling_temp = sampling_temp\n",
    "        self.diffusion_steps = diffusion_steps\n",
    "        self.num_seq_per_target = num_seq_per_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example data\n",
    "Below, we include three example input sets. Note that these are of varying difficulty and will exhibit different runtimes and resource utilizations.\n",
    "- Example 1R42 should run on most systems with 4 GPUs with 40GB of VRAM or more.\n",
    "- Example 5PTN\n",
    "- Example 6VXX requires 4 GPUs with 80GB of VRAM each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_6vxx = ExampleRequestParams(\n",
    "    target_sequence=\"MGILPSPGMPALLSLVSLLSVLLMGCVAETGTQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSSVLHSTQDLFLPFFSNVTWFHAIHVSGTNGTKRFDNPVLPFNDGVYFASTEKSNIIRGWIFGTTLDSKTQSLLIVNNATNVVIKVCEFQFCNDPFLGVYYHKNNKSWMESEFRVYSSANNCTFEYVSQPFLMDLEGKQGNFKNLREFVFKNIDGYFKIYSKHTPINLVRDLPQGFSALEPLVDLPIGINITRFQTLLALHRSYLTPGDSSSGWTAGAAAYYVGYLQPRTFLLKYNENGTITDAVDCALDPLSETKCTLKSFTVEKGIYQTSNFRVQPTESIVRFPNITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFSTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGKIADYNYKLPDDFTGCVIAWNSNNLDSKVGGNYNYLYRLFRKSNLKPFERDISTEIYQAGSTPCNGVEGFNCYFPLQSYGFQPTNGVGYQPYRVVVLSFELLHAPATVCGPKKSTNLVKNKCVNFNFNGLTGTGVLTESNKKFLPFQQFGRDIADTTDAVRDPQTLEILDITPCSFGGVSVITPGTNTSNQVAVLYQDVNCTEVPVAIHADQLTPTWRVYSTGSNVFQTRAGCLIGAEHVNNSYECDIPIGAGICASYQTQTNSPSGAGSVASQSIIAYTMSLGAENSVAYSNNSIAIPTNFTISVTTEILPVSMTKTSVDCTMYICGDSTECSNLLLQYGSFCTQLNRALTGIAVEQDKNTQEVFAQVKQIYKTPPIKDFGGFNFSQILPDPSKPSKRSFIEDLLFNKVTLADAGFIKQYGDCLGDIAARDLICAQKFNGLTVLPPLLTDEMIAQYTSALLAGTITSGWTFGAGAALQIPFAMQMAYRFNGIGVTQNVLYENQKLIANQFNSAIGKIQDSLSSTASALGKLQDVVNQNAQALNTLVKQLSSNFGAISSVLNDILSRLDPPEAEVQIDRLITGRLQSLQTYVTQQLIRAAEIRASANLAATKMSECVLGQSKRVDFCGKGYHLMSFPQSAPHGVVFLHVTYVPAQEKNFTTAPAICHDGKAHFPREGVFVSNGTHWFVTQRNFYEPQIITTDNTFVSGNCDVVIGIVNNTVYDPLQPELDSFKEELDKYFKNHTSPDVDLGDISGINASVVNIQKEIDRLNEVAKNLNESLIDLQELGKYEQYIKGSGRENLYFQGGGGSGYIPEAPRDGQAYVRKDGEWVLLSTFLGHHHHHHHH\",\n",
    "    contigs=\"A353-410/0 100-200\",\n",
    "    hotspot_res=[\"A360\",\"A361\",\"A362\",\"A366\"],\n",
    "    input_pdb_chains=[\"A\"],\n",
    "    ca_only=False,\n",
    "    use_soluble_model=False,\n",
    "    sampling_temp=[0.1],\n",
    "    diffusion_steps=15,\n",
    "    num_seq_per_target=20\n",
    ")\n",
    "example_5ptn = ExampleRequestParams(\n",
    "    target_sequence=\"NITEEFYQSTCSAVSKGYLSALRTGWYTSVITIELSNIKKIKCNGTDAKIKLIKQELDKYKNAVTELQLLMQSTPATNNQARGSGSGRSLGFLLGVGSAIASGVAVSKVLHLEGEVNKIKSALLSTNKAVVSLSNGVSVLTSKVLDLKNYIDKQLLPIVNKQSCSIPNIETVIEFQQKNNRLLEITREFSVNAGVTTPVSTYMLTNSELLSLINDMPITNDQKKLMSNNVQIVRQQSYSIMSIIKEEVLAYVVQLPLYGVIDTPCWKLHTSPLCTTNTKEGSNICLTRTDRGWYCDNAGSVSFFPQAETCKVQSNRVFCDTMNSLTLPSEVNLCNVDIFNPKYDCKIMTSKTDVSSSVITSLGAIVSCYGKTKCTASNKNRGIIKTFSNGCDYVSNKGVDTVSVGNTLYYVNKQEGKSLYVKGEPIINFYDPLVFPSDQFDASISQVNEKINQSLAFIRKSDELLSAIGGYIPEAPRDGQAYVRKDGEWVLLSTFLGGLVPRGSHHHHHH\",\n",
    "    contigs=\"A1-25/0 70-100\",\n",
    "    hotspot_res=[\"A14\",\"A15\",\"A17\",\"A18\"],\n",
    "    input_pdb_chains=[\"A\"],\n",
    "    ca_only=False,\n",
    "    use_soluble_model=False,\n",
    "    sampling_temp=[0.1],\n",
    "    diffusion_steps=15,\n",
    "    num_seq_per_target=20\n",
    ")\n",
    "example_1r42 = ExampleRequestParams(\n",
    "    target_sequence=\"STIEEQAKTFLDKFNHEAEDLFYQSSLASWNYNTNITEENVQNMNNAGDKWSAFLKEQSTLAQMYPLQEIQNLTVKLQLQALQQNGSSVLSEDKSKRLNTILNTMSTIYSTGKVCNPDNPQECLLLEPGLNEIMANSLDYNERLWAWESWRSEVGKQLRPLYEEYVVLKNEMARANHYEDYGDYWRGDYEVNGVDGYDYSRGQLIEDVEHTFEEIKPLYEHLHAYVRAKLMNAYPSYISPIGCLPAHLLGDMWGRFWTNLYSLTVPFGQKPNIDVTDAMVDQAWDAQRIFKEAEKFFVSVGLPNMTQGFWENSMLTDPGNVQKAVCHPTAWDLGKGDFRILMCTKVTMDDFLTAHHEMGHIQYDMAYAAQPFLLRNGANEGFHEAVGEIMSLSAATPKHLKSIGLLSPDFQEDNETEINFLLKQALTIVGTLPFTYMLEKWRWMVFKGEIPKDQWMKKWWEMKREIVGVVEPVPHDETYCDPASLFHVSNDYSFIRYYTRTLYQFQFQEALCQAAKHEGPLHKCDISNSTEAGQKLFNMLRLGKSEPWTLALENVVGAKNMNVRPLLNYFEPLFTWLKDQNKNSFVGWSTDWSPYAD\",\n",
    "    contigs=\"A114-353/0 50-100\",\n",
    "    hotspot_res=[\"A119\",\"A123\",\"A233\",\"A234\",\"A235\"],\n",
    "    input_pdb_chains=[\"A\"],\n",
    "    ca_only=False,\n",
    "    use_soluble_model=False,\n",
    "    sampling_temp=[0.1],\n",
    "    diffusion_steps=15,\n",
    "    num_seq_per_target=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set the example here to switch example inputs.\n",
    "## Note: Example 6vxx requires a GPU with at least 80GB of VRAM.\n",
    "example = example_5ptn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check that the NIM is ready from Python\n",
    "\n",
    "We can test whether each NIM is up and running using our check_nim_readiness function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = check_nim_readiness(NIM_PORTS.ALPHAFOLD2_PORT.value)\n",
    "print(f\"AlphaFold2 NIM is ready: {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = check_nim_readiness(NIM_PORTS.PROTEINMPNN_PORT.value)\n",
    "print(f\"ProteinMPNN NIM is ready: {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = check_nim_readiness(NIM_PORTS.RFDIFFUSION_PORT.value)\n",
    "print(f\"RFDiffusion NIM is ready: {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = check_nim_readiness(NIM_PORTS.AF2_MULTIMER_PORT.value)\n",
    "print(f\"AlphaFold2-multimer NIM is ready: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AlphaFold2\n",
    "\n",
    "AlphaFold2 is a deep learning model for predicting protein structure from amino acid sequence that has achieved state-of-the-art performance. The NVIDIA AlphaFold2 NIM includes GPU-accelerated MMseqs2, which accelerates the MSA portion of the structural prediction pipeline.\n",
    "\n",
    "**Inputs**:\n",
    "- `sequence`: An amino acid sequence\n",
    "- `algorithm`: The algorithm used for Multiple Sequence Alignment (MSA). This can be either of `jackhmmer` or `mmseqs2`. MMSeqs2 is significantly faster.\n",
    "\n",
    "**Outputs**:\n",
    "- A list of predicted structures in PDB format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## estimated runtime: ~25 minutes for example 1R42 on 1 A6000 GPU\n",
    "## 12 minutes on H100 for example 1R42\n",
    "alphafold2_query = {\n",
    "    \"sequence\" : example.target_sequence,\n",
    "    \"algorithm\" : \"mmseqs2\",\n",
    "}\n",
    "\n",
    "rc, alphafold2_response = query_nim(\n",
    "                                    payload=alphafold2_query,\n",
    "                                    nim_endpoint=NIM_ENDPOINTS.ALPHAFOLD2.value,\n",
    "                                    nim_port=NIM_PORTS.ALPHAFOLD2_PORT.value,\n",
    "                                    echo=True\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print the first two lines (160 characters) of the alphafold2 response\n",
    "alphafold2_response[0][0:160]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RFDiffusion\n",
    "\n",
    "This section demonstrates how to use RFDiffusion NIM in a *de novo* protein design workflow. Inspired by AI image generation models, RFDiffusion applies generative diffusion techniques to create novel protein structures. It excels in designing complex protein architectures, including binders and symmetric assemblies, by sculpting atomic clouds into functional proteins.\n",
    "\n",
    "**Inputs**\n",
    "- `input_pdb` is the protein target in PDB format\n",
    "- `contigs` is the RFDiffusion language for how to specify regions to work on. See the official [RFDiffusion repo](https://github.com/RosettaCommons/RFdiffusion?tab=readme-ov-file#running-the-diffusion-script) for a full breakdown. A20-60/0 50-100 means to generate a binder to chain A residue 20-60, where the binder is 50-100 residues long. The /0 specifies a chain break.\n",
    "- `hotspot_res` hot spot residues (specifically for binders)\n",
    "- `diffusion_steps` number of diffusion_steps\n",
    "\n",
    "**Output**:\n",
    "- `output_pdb` is the output pdb\n",
    "- `protein` is the input pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Expected runtime: ~15 seconds to 1 minute\n",
    "## H100 runtime: 9 seconds\n",
    "rfdiffusion_query = {\n",
    "        \"input_pdb\" : alphafold2_response[0], ## Take the first structure prediction (of 5) from AlphaFold2\n",
    "        \"contigs\" : \"51-51/A163-181/60-60\", #example.contigs\n",
    "        # \"hotspot_res\" : example.hotspot_res,\n",
    "        \"diffusion_steps\" : example.diffusion_steps\n",
    "    }\n",
    "\n",
    "rc, rfdiffusion_response = query_nim(\n",
    "    payload=rfdiffusion_query,\n",
    "    nim_endpoint=NIM_ENDPOINTS.RFDIFFUSION.value,\n",
    "    nim_port=NIM_PORTS.RFDIFFUSION_PORT.value\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print the first 160 characters of the RFDiffusion PDB output\n",
    "print(rfdiffusion_response[\"output_pdb\"][0:160])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ProteinMPNN\n",
    "ProteinMPNN (Protein Message Passing Neural Network) is a deep learning-based graph neural network used in *de novo* protein design workflows. It predicts amino acid sequences for given protein backbones, leveraging evolutionary, functional, and structural information to generate sequences that are likely to fold into the desired 3D structures. This tool integrates seamlessly with NIMs into workflows involving RFDiffusion for backbone generation and AlphaFold-2 Multimer for interaction prediction, enhancing the accuracy and efficiency of protein design.\n",
    "\n",
    "**Inputs**: \n",
    "- `input_pdb` Input protein for which amino acid sequences need to be predicted\n",
    "- `ca_only` Defaults to false, CA-only model helps to address specific needs in protein design where focusing on the alpha carbon (CA)\n",
    "- `use_soluble_model` ProteinMPNN offers soluble models for applications requiring high solubility and non-soluble models for membrane protein studies and industrial applications where solubility is less critical.\n",
    "- `num_seq_per_target` how many seqs to generate for a given target protein structure\n",
    "- `sampling_temp` ranges from 0 to 1 ranges from 0 to 1 and controls the diversity of design outcomes by adjusting the probability values for the 20 amino acids at each sequence position. Higher values increase\n",
    " \n",
    "**Outputs**:\n",
    "- `ProteinMPNN.fa` which is a fasta file containing the generated sequences for the given structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Expected runtime: < 30 seconds for 20 short sequences\n",
    "## H100 Runtime: 8 seconds\n",
    "proteinmpnn_query = {\n",
    "        \"input_pdb\" : rfdiffusion_response[\"output_pdb\"],\n",
    "        \"input_pdb_chains\" : example.input_pdb_chains,\n",
    "        \"ca_only\" : example.ca_only,\n",
    "        \"use_soluble_model\" : example.use_soluble_model,\n",
    "        \"num_seq_per_target\" : example.num_seq_per_target,\n",
    "        \"sampling_temp\" : example.sampling_temp\n",
    "}\n",
    "\n",
    "rc, proteinmpnn_response = query_nim(\n",
    "    payload=proteinmpnn_query,\n",
    "    nim_endpoint=NIM_ENDPOINTS.PROTEINMPNN.value,\n",
    "    nim_port=NIM_PORTS.PROTEINMPNN_PORT.value\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step, we'll extract FASTA sequences from the output FASTA file created by ProteinMPNN. Then, we'll create binder-target pairs that we can feed to AlphaFold2-Multimer to predict the binder-target complex structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta_sequences = [x.strip() for x in proteinmpnn_response[\"mfasta\"].split(\"\\n\") if '>' not in x][2:]\n",
    "\n",
    "binder_target_pairs = [[binder, example.target_sequence] for binder in fasta_sequences]\n",
    "\n",
    "print(f\"Generated {len(fasta_sequences)} FASTA sequences and {len(binder_target_pairs)} binder-target pairs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AlphaFold2-Multimer\n",
    "\n",
    "AlphaFold2-Multimer is a deep learning model that extends the AlphaFold2 pipelines to predict the combined structure a list of input peptide sequences. \n",
    "\n",
    "**Inputs**:\n",
    "\n",
    "- `sequences`: A list of peptide sequences. For this use case, a single pair of sequences (one peptide chain from the ProteinMPNN result plus the original protein sequence used as input to this workflow).\n",
    "- `algorithm`: The algorithm uses for Multiple Sequence Alignment (MSA). This can be either `jackhmmer` or `mmseqs2`. MMSeqs2 is significantly faster.\n",
    "\n",
    "**Output**:\n",
    "\n",
    "- A list of lists of predicted structures in PDB format. A list of five predictions is returned for each input binder-target pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Expected runtime: 20 min per binder-target pair.\n",
    "## Total runtime: roughly 3 hours\n",
    "n_processed = 0\n",
    "multimer_response_codes = [0 for i in binder_target_pairs]\n",
    "multimer_results = [None for i in binder_target_pairs]\n",
    "\n",
    "## NOTE: change this value to process more or fewer target-binder pairs.\n",
    "pairs_to_process = 1\n",
    "\n",
    "for binder_target_pair in binder_target_pairs:\n",
    "    multimer_query = {\n",
    "        \"sequences\" : binder_target_pair,\n",
    "        \"selected_models\" : [1]\n",
    "    }\n",
    "    print(f\"Processing pair number {n_processed+1} of {len(binder_target_pairs)}\")\n",
    "    rc, multimer_response = query_nim(\n",
    "        payload=multimer_query,\n",
    "        nim_endpoint=NIM_ENDPOINTS.AF2_MULTIMER.value,\n",
    "        nim_port=NIM_PORTS.AF2_MULTIMER_PORT.value\n",
    "    )\n",
    "    multimer_response_codes[n_processed] = rc\n",
    "    multimer_results[n_processed] = multimer_response\n",
    "    print(f\"Finished binder-target pair number {n_processed+1} of {len(binder_target_pairs)}\")\n",
    "    n_processed += 1\n",
    "    if n_processed >= pairs_to_process:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print just the first 160 characters of the first multimer response\n",
    "result_idx = 0\n",
    "prediction_idx = 0\n",
    "print(multimer_results[result_idx][prediction_idx][0:160])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing the predicted binders and structures\n",
    "\n",
    "There are many metrics that can be used to assess the quality of the predicted binder-target structure. The predicted local distance difference test (pLDDT) is a measure of per-residue confidence in the local structure. It has a range of zero to one hundred, with higher scores considered more accurate.\n",
    "\n",
    "The following snippet ranks the results of the binder-target pair AlphaFold2-Multimer predictions by their pLDDT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate average pLDDT over all residues \n",
    "def calculate_average_pLDDT(pdb_string):\n",
    "    total_pLDDT = 0.0\n",
    "    atom_count = 0\n",
    "    pdb_lines = pdb_string.splitlines()\n",
    "    for line in pdb_lines:\n",
    "        # PDB atom records start with \"ATOM\"\n",
    "        if line.startswith(\"ATOM\"):\n",
    "            atom_name = line[12:16].strip() # Extract atom name\n",
    "            if atom_name == \"CA\":  # Only consider atoms with name \"CA\"\n",
    "                try:\n",
    "                    # Extract the B-factor value from columns 61-66 (following PDB format specifications)\n",
    "                    pLDDT = float(line[60:66].strip())\n",
    "                    total_pLDDT += pLDDT\n",
    "                    atom_count += 1\n",
    "                except ValueError:\n",
    "                    pass  # Skip lines where B-factor can't be parsed as a float\n",
    "\n",
    "    if atom_count == 0:\n",
    "        return 0.0  # Return 0 if no N atoms were found\n",
    "\n",
    "    average_pLDDT = total_pLDDT / atom_count\n",
    "    return average_pLDDT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "plddts = []\n",
    "for idx in range(0, len(multimer_results)):\n",
    "    if multimer_results[idx] is not None:\n",
    "        plddts.append(calculate_average_pLDDT(multimer_results[idx][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combine the results with their pLDDTs\n",
    "binder_target_results = list(zip(binder_target_pairs, multimer_results, plddts))\n",
    "\n",
    "## Sort the results by plddt\n",
    "sorted_binder_target_results = sorted(binder_target_results, key=lambda x : x[2])\n",
    "\n",
    "## print the top 5 results\n",
    "for i in range(0, len(sorted_binder_target_results)):\n",
    "    print(\"-\"*80)\n",
    "    print(f\"rank: {i}\")\n",
    "    print(f\"binder: {sorted_binder_target_results[i][0][0]}\")\n",
    "    print(f\"target: {sorted_binder_target_results[i][0][1]}\")\n",
    "    print(f\"pLDDT: {sorted_binder_target_results[i][2]}\")\n",
    "    print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These sequences show the highest pLDDT for their binder-target pair."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
